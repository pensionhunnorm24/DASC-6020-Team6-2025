{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  },
  "title": "02_Modeling — Model development and evaluation"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_Modeling — Model development, evaluation, and screenshots\n",
    "\n",
    "This notebook trains multiple models, evaluates them on the test set, saves pipeline artifacts, and generates the evaluation figures (screenshots) required by the project specification."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from src.features import build_preprocessing\n",
    "from src.models.linear_models import linear_regression, ridge_regression, lasso_regression\n",
    "from src.models.tree_models import decision_tree, random_forest\n",
    "from src.models.boosting_models import xgboost_model\n",
    "from src.models.advanced_models import svr_model, mlp_model\n",
    "from src.evaluate import plot_pred_vs_true, plot_residuals_hist, plot_feature_importance\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "ARTIFACTS = Path('artifacts')\n",
    "FIG_DIR = Path('reports/figures')\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train = pd.read_csv(DATA_DIR / 'train.csv')\n",
    "test = pd.read_csv(DATA_DIR / 'test.csv')\n",
    "X_train = train[['trip_duration_days','miles_traveled','total_receipts_amount']]\n",
    "y_train = train['reimbursement_amount']\n",
    "X_test = test[['trip_duration_days','miles_traveled','total_receipts_amount']]\n",
    "y_test = test['reimbursement_amount']\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "preproc = build_preprocessing(poly_degree=2)\n",
    "X_train_t = preproc.fit_transform(X_train)\n",
    "X_test_t = preproc.transform(X_test)\n",
    "print('Preprocessing complete. Transformed feature shape:', X_train_t.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train models (examples)\n",
    "At least four model families are trained as required by the specification."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "models = {\n",
    "    'linear': linear_regression(),\n",
    "    'ridge': ridge_regression(alpha=1.0),\n",
    "    'rf': random_forest(n_estimators=100),\n",
    "    'xgb': xgboost_model(n_estimators=100),\n",
    "    'svr': svr_model(C=1.0),\n",
    "    'mlp': mlp_model(hidden_layer_sizes=(50,50), max_iter=500)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train_t, y_train)\n",
    "    preds = model.predict(X_test_t)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    results[name] = {'mae': mae, 'rmse': rmse}\n",
    "    # Save pipeline artifact (preproc + model)\n",
    "    joblib.dump({'preproc': preproc, 'model': model}, ARTIFACTS / f\"{name}_pipeline.joblib\")\n",
    "    print(f\"{name}: MAE={mae:.4f}, RMSE={rmse:.4f}\")\n",
    "\n",
    "results"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate evaluation figures (screenshots)\n",
    "For each saved pipeline we create: Pred vs True scatter, residual histogram, and feature importance (or placeholder)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for pipeline_file in ARTIFACTS.glob(\"*_pipeline.joblib\"):\n",
    "    name = pipeline_file.stem.replace(\"_pipeline\", \"\")\n",
    "    print('Generating figures for', name)\n",
    "    data = joblib.load(pipeline_file)\n",
    "    preproc = data['preproc']\n",
    "    model = data['model']\n",
    "    X_t = preproc.transform(X_test)\n",
    "    preds = model.predict(X_t)\n",
    "    # Pred vs True\n",
    "    plot_pred_vs_true(y_test, preds, name)\n",
    "    # Residuals\n",
    "    plot_residuals_hist(y_test, preds, name)\n",
    "    # Feature names from polynomial features if available\n",
    "    try:\n",
    "        poly = preproc.named_steps.get('poly')\n",
    "        base_features = ['trip_duration_days','miles_traveled','total_receipts_amount']\n",
    "        feat_names = poly.get_feature_names_out(base_features)\n",
    "    except Exception:\n",
    "        feat_names = [f\"f{i}\" for i in range(X_t.shape[1])]\n",
    "    # Feature importance or coefficients\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        plot_feature_importance(model.feature_importances_, feat_names, name)\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        coef = model.coef_.ravel()\n",
    "        plot_feature_importance(coef, feat_names, name)\n",
    "    else:\n",
    "        plt.figure(figsize=(6,2))\n",
    "        plt.text(0.5, 0.5, 'No feature importance available', ha='center', va='center')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIG_DIR / f\"{name}_feature_importance.png\", dpi=150)\n",
    "        plt.close()\n",
    "print('All figures generated in reports/figures/')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ensemble (optional)\n",
    "Example stacking ensemble using RandomForest and XGBoost (or fallback)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "estimators = [\n",
    "    ('rf', random_forest(n_estimators=100)),\n",
    "    ('xgb', xgboost_model(n_estimators=100))\n",
    "]\n",
    "stack = StackingRegressor(estimators=estimators, final_estimator=RidgeCV())\n",
    "stack.fit(X_train_t, y_train)\n",
    "preds = stack.predict(X_test_t)\n",
    "print('Ensemble MAE =', mean_absolute_error(y_test, preds))\n",
    "joblib.dump({'preproc': preproc, 'model': stack}, ARTIFACTS / 'ensemble_pipeline.joblib')\n",
    "plot_pred_vs_true(y_test, preds, 'ensemble')\n",
    "plot_residuals_hist(y_test, preds, 'ensemble')\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Next steps\n",
    "- Hyperparameter tuning (GridSearchCV / RandomizedSearchCV)\n",
    "- Interpretability (SHAP/LIME) and business-rule extraction\n",
    "- Productionize the best pipeline and validate performance under time constraints"
   ]
  }
 ]
}