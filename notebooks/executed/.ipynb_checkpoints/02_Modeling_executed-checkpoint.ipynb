{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "auto-prepare-02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T06:36:22.573875Z",
     "iopub.status.busy": "2025-12-04T06:36:22.573532Z",
     "iopub.status.idle": "2025-12-04T06:36:23.150460Z",
     "shell.execute_reply": "2025-12-04T06:36:23.149301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Train shape: (750, 3) Test shape: (250, 3)\n"
     ]
    }
   ],
   "source": [
    "# Auto-prepare data and ensure project root on sys.path (robust)\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def find_project_root(start: Path = None) -> Path:\n",
    "    if start is None:\n",
    "        start = Path.cwd()\n",
    "    cur = start.resolve()\n",
    "    root = Path(cur.root)\n",
    "    while True:\n",
    "        if (cur / 'src').is_dir():\n",
    "            return cur\n",
    "        if cur == root:\n",
    "            return start\n",
    "        cur = cur.parent\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "train_path = DATA_DIR / 'train.csv'\n",
    "test_path = DATA_DIR / 'test.csv'\n",
    "\n",
    "def prepare_data_via_import(json_path: Path):\n",
    "    import importlib\n",
    "    try:\n",
    "        dl = importlib.import_module('src.data_loader')\n",
    "        dl.prepare_datasets(str(json_path))\n",
    "        return True, None\n",
    "    except Exception as e:\n",
    "        return False, e\n",
    "\n",
    "def prepare_data_via_subprocess(json_path: Path):\n",
    "    cmd = [sys.executable, '-m', 'src.data_loader', str(json_path)]\n",
    "    try:\n",
    "        subprocess.check_call(cmd)\n",
    "        return True, None\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return False, e\n",
    "\n",
    "if not train_path.exists() or not test_path.exists():\n",
    "    print('data/train.csv or data/test.csv not found. Attempting to create them...')\n",
    "    json_path = DATA_DIR / 'public_cases.json'\n",
    "    if not json_path.exists():\n",
    "        raise FileNotFoundError(f'Expected JSON not found at {json_path}. Please place public_cases.json in data/')\n",
    "    ok, err = prepare_data_via_import(json_path)\n",
    "    if not ok:\n",
    "        print('Import approach failed, trying subprocess approach...')\n",
    "        ok2, err2 = prepare_data_via_subprocess(json_path)\n",
    "        if not ok2:\n",
    "            raise FileNotFoundError(\n",
    "                'Could not prepare data/train.csv and data/test.csv automatically. ' \n",
    "                f'Import error: {err}; Subprocess error: {err2}.\\nRun `python -m src.data_loader data/public_cases.json` from the project root.'\n",
    "            )\n",
    "    print('Data preparation completed.')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "ARTIFACTS = PROJECT_ROOT / 'artifacts'\n",
    "FIG_DIR = PROJECT_ROOT / 'reports' / 'figures'\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "X_train = train[['trip_duration_days','miles_traveled','total_receipts_amount']]\n",
    "y_train = train['reimbursement_amount']\n",
    "X_test = test[['trip_duration_days','miles_traveled','total_receipts_amount']]\n",
    "y_test = test['reimbursement_amount']\n",
    "\n",
    "print('Data loaded. Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-modeling-01",
   "metadata": {},
   "source": [
    "# 02_Modeling â€” Model development, evaluation, and screenshots\n",
    "\n",
    "This notebook trains multiple models, evaluates them on the test set, saves pipeline artifacts, and generates the evaluation figures (screenshots) required by the project specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "modeling-setup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T06:36:23.154450Z",
     "iopub.status.busy": "2025-12-04T06:36:23.154280Z",
     "iopub.status.idle": "2025-12-04T06:36:23.728857Z",
     "shell.execute_reply": "2025-12-04T06:36:23.728149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Transformed feature shape: (750, 20)\n"
     ]
    }
   ],
   "source": [
    "from src.features import build_preprocessing\n",
    "from src.models.linear_models import linear_regression, ridge_regression, lasso_regression\n",
    "from src.models.tree_models import decision_tree, random_forest\n",
    "from src.models.boosting_models import xgboost_model\n",
    "from src.models.advanced_models import svr_model, mlp_model\n",
    "from src.evaluate import plot_pred_vs_true, plot_residuals_hist, plot_feature_importance\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "preproc = build_preprocessing(poly_degree=2)\n",
    "X_train_t = preproc.fit_transform(X_train)\n",
    "X_test_t = preproc.transform(X_test)\n",
    "print('Preprocessing complete. Transformed feature shape:', X_train_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modeling-train",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T06:36:23.731086Z",
     "iopub.status.busy": "2025-12-04T06:36:23.730752Z",
     "iopub.status.idle": "2025-12-04T06:36:25.007739Z",
     "shell.execute_reply": "2025-12-04T06:36:25.005532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training linear...\n",
      "linear: MAE=117.8921, RMSE=170.5083\n",
      "Training ridge...\n",
      "ridge: MAE=118.0830, RMSE=169.9742\n",
      "Training rf...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf: MAE=80.3960, RMSE=138.5883\n",
      "Training xgb...\n",
      "xgb: MAE=87.8625, RMSE=147.4448\n",
      "Training svr...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svr: MAE=307.3183, RMSE=406.8359\n",
      "Training mlp...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp: MAE=100.2183, RMSE=154.7588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ECU\\Assignment\\Machine Learning\\legacy-reimbursement\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'linear': {'mae': 117.89206460704962, 'rmse': 170.50833741254093},\n",
       " 'ridge': {'mae': 118.0830156473711, 'rmse': 169.97423723808},\n",
       " 'rf': {'mae': 80.3960492, 'rmse': 138.58827349731325},\n",
       " 'xgb': {'mae': 87.86254806396485, 'rmse': 147.44480892379417},\n",
       " 'svr': {'mae': 307.3183143146941, 'rmse': 406.8358724488405},\n",
       " 'mlp': {'mae': 100.2182808513316, 'rmse': 154.75876065554516}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    'linear': linear_regression(),\n",
    "    'ridge': ridge_regression(alpha=1.0),\n",
    "    'rf': random_forest(n_estimators=100),\n",
    "    'xgb': xgboost_model(n_estimators=100),\n",
    "    'svr': svr_model(C=1.0),\n",
    "    'mlp': mlp_model(hidden_layer_sizes=(50,50), max_iter=500)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f'Training {name}...')\n",
    "    try:\n",
    "        model.fit(X_train_t, y_train)\n",
    "        preds = model.predict(X_test_t)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        mse = mean_squared_error(y_test, preds)\n",
    "        rmse = float(np.sqrt(mse))\n",
    "        results[name] = {'mae': mae, 'rmse': rmse}\n",
    "        joblib.dump({'preproc': preproc, 'model': model}, ARTIFACTS/f\"{name}_pipeline.joblib\")\n",
    "        print(f\"{name}: MAE={mae:.4f}, RMSE={rmse:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f'Model {name} failed: {e}')\n",
    "        results[name] = {'error': str(e)}\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "modeling-figures",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T06:36:25.013986Z",
     "iopub.status.busy": "2025-12-04T06:36:25.013411Z",
     "iopub.status.idle": "2025-12-04T06:36:26.798261Z",
     "shell.execute_reply": "2025-12-04T06:36:26.797536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating figures for linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating figures for mlp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating figures for rf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating figures for ridge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating figures for svr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating figures for xgb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All figures generated in reports/figures/\n"
     ]
    }
   ],
   "source": [
    "for pipeline_file in ARTIFACTS.glob(\"*_pipeline.joblib\"):\n",
    "    name = pipeline_file.stem.replace(\"_pipeline\", \"\")\n",
    "    print('Generating figures for', name)\n",
    "    data = joblib.load(pipeline_file)\n",
    "    preproc = data['preproc']\n",
    "    model = data['model']\n",
    "    X_t = preproc.transform(X_test)\n",
    "    preds = model.predict(X_t)\n",
    "    plot_pred_vs_true(y_test, preds, name)\n",
    "    plot_residuals_hist(y_test, preds, name)\n",
    "    try:\n",
    "        poly = preproc.named_steps.get('poly')\n",
    "        base_features = ['trip_duration_days','miles_traveled','total_receipts_amount']\n",
    "        feat_names = poly.get_feature_names_out(base_features)\n",
    "    except Exception:\n",
    "        feat_names = [f'f{i}' for i in range(X_t.shape[1])]\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        plot_feature_importance(model.feature_importances_, feat_names, name)\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        coef = model.coef_.ravel()\n",
    "        plot_feature_importance(coef, feat_names, name)\n",
    "    else:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(6,2))\n",
    "        plt.text(0.5, 0.5, 'No feature importance available', ha='center', va='center')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIG_DIR / f\"{name}_feature_importance.png\", dpi=150)\n",
    "        plt.close()\n",
    "print('All figures generated in reports/figures/')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
